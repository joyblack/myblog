# 简介
通过本教程您可以学习到:
1. HDFS概念
2. HDFS的组成
3. HDFS文件块大小

# 1、HDFS概念
HDFS，它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。

HDFS的设计适合一次写入，多次读出的场景，且不支持文件的修改。适合用来做数据分析，并不适合用来做网盘应用。

> 之所以不适合修改，是因为HDFS底层存储逻辑以及其应用目的决定的。首先其应用目的是用于海量的数据分析，这当然不会去对文件的读、写两方面进行兼顾；再加上底层是将文件进行了分块的（128M一块），修改文件内容首先要合并、然后在写入，又在切分，也许差强人意，但是真正的网盘应用不适合用他做的，推荐CEPH。

# 2、HDFS的组成
在Hadoop的简介章节我们已经介绍过这里的知识了，这里我们在回顾一遍。

HDFS集群包括，NameNode和DataNode以及Secondary Namenode。其中：
* NameNode负责管理整个文件系统的元数据，以及每一个路径（文件）所对应的数据块信息。
* DataNode 负责管理用户的文件数据块，每一个数据块都可以在多个datanode上存储多个副本。
* Secondary NameNode用来监控HDFS状态的辅助后台程序(辅助namenode)，每隔一段时间获取HDFS元数据的快照。

# 3、HDFS文件块大小
1、HDFS中的文件在物理上是分块存储（block），块的大小可以通过配置参数( dfs.blocksize)来规定，默认大小在hadoop2.x版本中是128M，老版本中是64M；

2、HDFS的块比磁盘的块大，其目的是为了最小化寻址开销。如果块设置得足够大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间。因而，传输一个由多个块组成的文件的时间取决于磁盘传输速率。

在通常情况下，寻址时间约为10ms，而传输速率为100MB/s，为了使寻址时间仅占传输时间的1%，我们要将块大小设置约为100MB。默认的块大小实际为64MB，但是很多情况下HDFS使用128MB的块设置。

块的大小：10ms*100*100M/s = 100M
> 这条公式的原理是普遍认同的定律：寻址时间为传输时间的1%为传输的最佳状态。

> 也就说文件块的大小设置原理是从寻址时间和传输时间而来的。

# 参考
本系列的文章参考资料来源有3个地方：
1. 尚硅谷官方大数据教学视频。
2. 书籍《hadoop权威指南 第四版》
3. 官方文档。